<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://rts-coder.github.io/blog_rts.github.io/</id>
    <title>Gridea</title>
    <updated>2020-11-10T13:01:14.375Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://rts-coder.github.io/blog_rts.github.io/"/>
    <link rel="self" href="https://rts-coder.github.io/blog_rts.github.io/atom.xml"/>
    <subtitle>任太帅的个人博客</subtitle>
    <logo>https://rts-coder.github.io/blog_rts.github.io/images/avatar.png</logo>
    <icon>https://rts-coder.github.io/blog_rts.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[Pytorch 基本数据类型]]></title>
        <id>https://rts-coder.github.io/blog_rts.github.io/post/pytorch-ji-ben-shu-ju-lei-xing/</id>
        <link href="https://rts-coder.github.io/blog_rts.github.io/post/pytorch-ji-ben-shu-ju-lei-xing/">
        </link>
        <updated>2020-11-10T12:53:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="pytorch-基本数据类型">Pytorch 基本数据类型</h1>
<h2 id="基本类型">基本类型</h2>
<p>在python中的数据类型在pytorch中基本都能一一对应，除了string</p>
<figure data-type="image" tabindex="1"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108163412335.png" alt="image-20201108163412335" loading="lazy"></figure>
<p>pytorch并没有string类型，但是可以使用编码类型来表示。比如10表示小狗，01表示猫。在nlp中有专门的模块来解决这个问题。</p>
<figure data-type="image" tabindex="2"><img src="https://i.loli.net/2020/11/08/j5yW3cgzYL2flqH.png" alt="image-20201108140444027" loading="lazy"></figure>
<p>pytorch中的数据类型</p>
<figure data-type="image" tabindex="3"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108165053338.png" alt="image-20201108165053338" loading="lazy"></figure>
<h2 id="查看类型">查看类型</h2>
<p>a.type()   是torch中的方法，可以返回详细的类型</p>
<p>type(a)   是python自带的方法，没有提供额外信息</p>
<p>isinstance(a,torch.FloatTensor)   一般用这种方法来比对类型</p>
<figure data-type="image" tabindex="4"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108165146443.png" alt="image-20201108165146443" loading="lazy"></figure>
<p>数据放置于cpu和GPU上所表示的数据类型是不同的</p>
<figure data-type="image" tabindex="5"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108165232186.png" alt="image-20201108165232186" loading="lazy"></figure>
<h3 id="dim0">dim0</h3>
<p>torch.tensor(1.3) ：对于标量数据类型可以使用该方法来创建一个0维数组。</p>
<p>a.shape  ： 可以查看tensor张量的形状</p>
<p>a.size()   :   与a.shape 对应，不同之处在于一个直接是属性，另一个是函数。</p>
<figure data-type="image" tabindex="6"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108165340645.png" alt="image-20201108165340645" loading="lazy"></figure>
<h3 id="dim1">dim1</h3>
<p>一维数据的生成</p>
<p>torch.tensor([1])  : 这个方法圆括号里面有中括号，会根据里面的值生成一维张量。</p>
<p>torch.FloatTensor()  :   当里面只给出了一个数字，则会根据数字生成未初始化的相应一维张量。如果里面有中括号，则会根据中括号的内容生成一维张量。</p>
<figure data-type="image" tabindex="7"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108165454724.png" alt="image-20201108165454724" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108165755457.png" alt="image-20201108165755457" loading="lazy"></figure>
<p>将numpy中的一维数组转换为一维tensor张量。</p>
<figure data-type="image" tabindex="9"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108165550471.png" alt="image-20201108165550471" loading="lazy"></figure>
<h3 id="dim2">dim2</h3>
<p>下面使用随机正态分布创建了一个dim为2的张量。</p>
<p>size函数如果不给值，则返回整个的形状。如果给了参数，则返回的是该维度上的形状大小。</p>
<figure data-type="image" tabindex="10"><img src="https://i.loli.net/2020/11/08/jhToHpysAnf9KeS.png" alt="image-20201108134412844" loading="lazy"></figure>
<p>dim3</p>
<p>下面使用随机均匀分布创建一个dim为3的张量。如20句话，每句话10个单词，每个单词用100个分量的向量表示，得到的Tensor就是shape=[20, 10, 100]</p>
<p>可以使用list方法直接将数据转换为列表。方便和python的交互。</p>
<p>三维数据适合文字处理。</p>
<figure data-type="image" tabindex="11"><img src="https://i.loli.net/2020/11/08/qcIK7OVPjLiE1F4.png" alt="image-20201108134855997" loading="lazy"></figure>
<h3 id="dim4">dim4</h3>
<p>a = torch.rand(2,3,28,28)</p>
<p>dim为4的张量经常用来表示图片。从左往右，第一个数字表示有几张图片，第二个数字表示rgb的第几个通道，比如1表示灰色图片，3表示彩色图片。第三、第四分别表示图片的长和宽。</p>
<p>例如100张MNIST数据集的灰度图(通道数为1，如果是RGB图像通道数就是3)，每张图高28像素，宽28像素，那么这个Tensor的shape=[100, 1, 28, 28]，也就是一个batch的数据维度：[batch_size, channel, height, width]。</p>
<p><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/hazne6m8CrWsVFl.png" alt="image-20201108135153302" loading="lazy"><img src="https://i.loli.net/2020/11/08/Q8iL69lxgAzmfRT.png" alt="image-20201108135206069" loading="lazy"></p>
<h3 id="额外知识">额外知识</h3>
<p>torch.numel()   :    得到tensor数据的具体大小。</p>
<p>torch.dim()    :   和length(a.shape)   方法一样，返回的数据表示tensor张量的维度大小。</p>
<figure data-type="image" tabindex="12"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108140109173.png" alt="image-20201108140109173" loading="lazy"></figure>
<h2 id="创建tensor">创建tensor</h2>
<h3 id="导入数据">导入数据</h3>
<p>从numpy导入数据</p>
<p>导入的数据值和数据类型不变，只是从numpy数组变为了张量。</p>
<figure data-type="image" tabindex="13"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/SHexq4T85wuO9Ec.png" alt="image-20201101142624144" loading="lazy"></figure>
<p>从list导入数据。</p>
<p>torch.tensor()  根据数据生成张量，建议有数据的情况尽量使用小写的生成，有助于区分。</p>
<p>torch.FloatTensor()    既可以根据已有数据来生成，也可以根据给出的shape数据生成。</p>
<figure data-type="image" tabindex="14"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108143007496.png" alt="image-20201108143007496" loading="lazy"></figure>
<h3 id="创建未初始化张量">创建未初始化张量</h3>
<p>torch.empty()  ：给定shape可以生成未初始化的数据。</p>
<p>torch.FloatTensor( )  :  给定shape可以生成未初始化的数据。也可以根据具体的数据生成张量。</p>
<p>生成的额数据是随机的，可能很大或者很小，一般不能直接用于计算，需要后续的赋值。</p>
<figure data-type="image" tabindex="15"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110193515679.png" alt="image-20201110193515679" loading="lazy"></figure>
<h3 id="初始化张量">初始化张量</h3>
<p>torch.rand()   : 初始化的每一个数据都是在从0 到1 之间随机均匀选取的。</p>
<p>torch.rand_like()  :  接收的是一个tensor张量，读取其shape数据，之后再用torch.rand()进行从0到1的随机均匀选取。</p>
<p>torch.randint(low,high,size)  :  这个方法前两个参数是取值的范围，左闭右开。第三个参数是传入一个tuple类型的size参数。</p>
<figure data-type="image" tabindex="16"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108143228905.png" alt="image-20201108143228905" loading="lazy"></figure>
<p>torch.randn(3,3)    :   根据正态化生成数据，N(0,1),  以0为均值，以1为方差生成数据。</p>
<p>torch.normal(mean=3 ,std=torch.arange(1,0,-0.1))    :  mean是生成数据的平均值，std是数据的方差，后面表示方差从1到0以步长0.1减小。也可以只填写前面两个值，默认步长为1。后面括号中的参数，需要包含浮点数，全是小数的时候会报错。</p>
<figure data-type="image" tabindex="17"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201108143333136.png" alt="image-20201108143333136" loading="lazy"></figure>
<p>torch.full([2,3],5)  :   表示生成一个2*3的矩阵，里面的数据全部是5。数据的类型为默认类型。</p>
<p>若需要生成标量，则传入中括号空值；生成一维tensor张量只需要传入1就行。</p>
<figure data-type="image" tabindex="18"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110194028715.png" alt="image-20201110194028715" loading="lazy"></figure>
<p>torch.arange(0,10)   :   生成从0开始到但不包括10的等差数列。也可以传入一个数作为步长。</p>
<p>torch.range(0,10)   :  也可以实现上面函数一样的功能。但该函数之后会被删除，所以不推荐使用。</p>
<figure data-type="image" tabindex="19"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110194130047.png" alt="image-20201110194130047" loading="lazy"></figure>
<p>torch.linspace(start, end, steps) ： 从start到end之间（两数闭区间）按照steps进行均分，之后返回steps个数这么多的等差数列。</p>
<p>torch.logspace(start, end, steps，base) ： 取得的是两个数的对数，在两个数之间以步数取均值。比如第三个例子是从10的0次方到10的-1次方，平均来取。base是设置对数的基数，默认值为10.</p>
<figure data-type="image" tabindex="20"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110194337912.png" alt="image-20201110194337912" loading="lazy"></figure>
<p>torch.ones()  :  生成全是1的张量，维度由传入的数字确定，可以传入元组或者列表。</p>
<p>torch.zeros()  : 同上</p>
<p>torch.eye():   生成对角矩阵，但是传入的参数，只能是两个或者一个。更高维度的将不适用。</p>
<figure data-type="image" tabindex="21"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110194516813.png" alt="image-20201110194516813" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110194540300.png" alt="image-20201110194540300" loading="lazy"></figure>
<p>torch.randperm(n)   :  生成0到n-1 的一维张量，顺序是打散了的。</p>
<figure data-type="image" tabindex="23"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110194905773.png" alt="image-20201110194905773" loading="lazy"></figure>
<p>运用的例子。比如数据的第一排表示的是人，后面分别表示的是数学成绩和语文成绩，我们希望两个数据集能够同步。比如人都从第一行换到第二行。</p>
<figure data-type="image" tabindex="24"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110194930648.png" alt="image-20201110194930648" loading="lazy"></figure>
<h3 id="设置默认类型">设置默认类型</h3>
<p>torch.tensor()  :   里面的数据类型会给定默认的数据类型。比如整数为LongTensor类型张量，小数的为默认设置的张量类型。生成的torsor张量数据类型不会被默认类型改变。</p>
<p>torch.Tensor（）：无论是整数还是小数，全部设置为默认的tensor类型。生成的tensor数据类型会受到默认设置的改变。</p>
<p>torch.set_default_tensor_type(torch.DoubleTensor)     使用该方法可以设置默认类型。</p>
<figure data-type="image" tabindex="25"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110195516251.png" alt="image-20201110195516251" loading="lazy"></figure>
<figure data-type="image" tabindex="26"><img src="https://cdn.jsdelivr.net/gh/rts-coder/pytorch-learning/img/image-20201110195538602.png" alt="image-20201110195538602" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[关于个人博客]]></title>
        <id>https://rts-coder.github.io/blog_rts.github.io/post/guan-yu-ge-ren-bo-ke/</id>
        <link href="https://rts-coder.github.io/blog_rts.github.io/post/guan-yu-ge-ren-bo-ke/">
        </link>
        <updated>2020-11-04T04:54:16.000Z</updated>
        <content type="html"><![CDATA[<p>这是我的个人博客，我是任太帅。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://rts-coder.github.io/blog_rts.github.io/post/hello-gridea/</id>
        <link href="https://rts-coder.github.io/blog_rts.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>